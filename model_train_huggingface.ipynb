{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lundm/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoFeatureExtractor  , AutoModelForImageClassification, TrainingArguments, Trainer, MobileNetV2ForImageClassification\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=1001, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load  dataset\n",
    "dataset = load_dataset(\"Piro17/dataset-affecthqnet-fer2013\")\n",
    "#dataset = load_dataset(\"AutumnQiu/fer2013\")\n",
    "\n",
    "sample_train = 40000\n",
    "sample_test = int(sample_train / 8)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset['test'] = dataset['train'].shuffle(seed=96).select(range(sample_test))\n",
    "dataset['train'] = dataset['train'].shuffle(seed=23).select(range(sample_train))\n",
    "\n",
    "test_valid_split = dataset['test'].train_test_split(test_size=0.65, seed=45)\n",
    "dataset['test'] = test_valid_split['train']\n",
    "dataset['validation'] = test_valid_split['test']\n",
    "\n",
    "\n",
    "#Import Model from HuggingFace\n",
    "model = \"google/mobilenet_v2_1.0_224\"\n",
    "#model = \"microsoft/resnet-26\"\n",
    "#model = \"microsoft/resnet-50\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model)\n",
    "model = MobileNetV2ForImageClassification.from_pretrained(model)\n",
    "\n",
    "label2id = {\n",
    "    \"angry\": 0,\n",
    "    \"disgust\": 1,\n",
    "    \"fear\": 2,\n",
    "    \"happy\": 3,\n",
    "    \"sad\": 4,\n",
    "    \"surprise\": 5,\n",
    "    \"neutral\": 6,\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "#Fix up the id2label and label2id configurations (Ensure it is consistent with the dataset)\n",
    "model.config.label2id = label2id\n",
    "model.config.id2label = id2label\n",
    "\n",
    "feature_extractor.label2id = label2id\n",
    "feature_extractor.id2label = id2label\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model label2id: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'sad': 4, 'surprise': 5, 'neutral': 6}\n",
      "Model id2label: {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'sad', 5: 'surprise', 6: 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model label2id:\", model.config.label2id)\n",
    "print(\"Model id2label:\", model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transform function\n",
    "def transform(example_batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    inputs = feature_extractor([img.convert(\"RGB\") for img in example_batch['image']], return_tensors='pt')\n",
    "    inputs['labels'] = example_batch['label']\n",
    "    return inputs\n",
    "\n",
    "# Apply the transform to the datasets\n",
    "dataset['train'] = dataset['train'].map(transform, batched=True)\n",
    "dataset['validation'] = dataset['validation'].map(transform, batched=True)\n",
    "\n",
    "# Remove the 'image' column as it's now transformed\n",
    "dataset['train'] = dataset['train'].remove_columns(['image'])\n",
    "dataset['validation'] = dataset['validation'].remove_columns(['image'])\n",
    "\n",
    "# Set the format for PyTorch\n",
    "dataset.set_format(type='torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'pixel_values', 'labels'],\n",
      "    num_rows: 3250\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Convert numeric labels to string labels\n",
    "    predicted_labels = [id2label[p] for p in predictions]\n",
    "    true_labels = [id2label[l] for l in labels]\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')  # Use 'weighted' for multi-class\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Args\n",
    "warmup = int(sample_train*0.1)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./huggingface_fer_model/results',\n",
    "    num_train_epochs=25,\n",
    "    per_device_train_batch_size=27,\n",
    "    per_device_eval_batch_size=27,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./huggingface_fer_model/logs',\n",
    "    logging_steps=25,\n",
    "    warmup_steps= warmup,\n",
    "    report_to=[],\n",
    "    learning_rate=6e-5,\n",
    "    weight_decay=0.075,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=2,\n",
    "    fp16 = True,\n",
    "    optim= 'adamw_torch_fused',\n",
    ")\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5928' max='37050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5928/37050 24:21 < 2:07:55, 4.05 it/s, Epoch 4/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.485920</td>\n",
       "      <td>0.861846</td>\n",
       "      <td>0.861842</td>\n",
       "      <td>0.863826</td>\n",
       "      <td>0.861846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.486559</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.872106</td>\n",
       "      <td>0.874935</td>\n",
       "      <td>0.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.685520</td>\n",
       "      <td>0.850462</td>\n",
       "      <td>0.852145</td>\n",
       "      <td>0.862026</td>\n",
       "      <td>0.850462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.645629</td>\n",
       "      <td>0.884308</td>\n",
       "      <td>0.884355</td>\n",
       "      <td>0.886129</td>\n",
       "      <td>0.884308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5928, training_loss=0.15162198367188012, metrics={'train_runtime': 1461.9971, 'train_samples_per_second': 683.996, 'train_steps_per_second': 25.342, 'total_flos': 5.0666323083264e+17, 'train_loss': 0.15162198367188012, 'epoch': 4.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4859\n",
      "Validation Accuracy: 0.8618\n",
      "Validation Precision: 0.8638\n",
      "Validation Recall: 0.8618\n",
      "Validation F1 Score: 0.8618\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Validation Loss: {eval_results['eval_loss']:.4f}\")\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']:.4f}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']:.4f}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./mobilenet_v2_affectnethq-fer2013_model_fixed_labels/preprocessor_config.json']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = './mobilenet_v2_affectnethq-fer2013_model_fixed_labels'\n",
    "model.save_pretrained(output)\n",
    "feature_extractor.save_pretrained(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
